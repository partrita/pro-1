import time
import torch
from typing import List

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

import pytest
from stability_reward import StabilityRewardCalculator
def get_sample_sequences(n: int = 4) -> List[str]:
    """Generate sample protein sequences for testing with varying lengths."""
    sequences = [
        "MGSRRITLLGALFAVLAVAIEGRTLLTHNLKAEAAETVDAVSSVVAGSAGRQLLVSEPHDYNYEKVGFDWTGGVCVNTGTSKQSPINIETDSLAEESERLGTADDTSRLALKGLLSSSYQLTSEVAINLEQDMQFSFNAPDEDLPQLTIGGVVHTFKPVQIHFHHFASEHAIDGQLYPLEAHMVMASQNDGSDQLAVIGIMYKYGEEDPFLKRLQETAQSNGEAGDKNVELNSFSINVARDLLPESDLTYYGYDGSLTTPGCDERVKWHVFKEARTVSVAQLKVFSEVTLAAHPEATVTNNRVIQPLNGRKVYEYKGEPNDKYNYVQHGFDWRDNGLDSCAGDVQSPIDIVTSTLQAGSSRSDVSSVNLMTLNTDAFTLTGNTVNIGQGMQINFGDPPAGDLPVIRIGTRDVTFRPLQVHWHFFLSEHTVDGVHYPLEAHIVMKDNDNLGDSAGQLAVIGIMYKYGDADPFITDMQKRVSDKIASGAITYGQSGVSLNNPDDPFNVNIKNNFLPSELGYAGYDGSLTTPPCSEIVKWHVFLEPRTVSVEQMEVFADVTLNSNPGATVTTNRMIQPLEGRTVYGYNGAAA",  # Carbonic anhydrase sequence
        "MGSRRITLLGALFAVLAVAIEGRTLLTHNLKAEAAETVDAVSSVVAGSAGRQLLVSEPHDYNYEKVGFDWTGGVCVNTGTSKQSPINIETDSLAEESERLGTADDTSRLALKGLLSSSYQLTSEVAINLEQDMQFSFNAPDEDLPQLTIGGVVHTFKPVQIHFHHFASEHAIDGQLYPLEAHMVMASQNDGSDQLAVIGIMYKYGEEDPFLKRLQETAQSNGEAGDKNVELNSFSINVARDLLPESDLTYYGYDGSLTTPGCDERVKWHVFKEARTVSVAQLKVFSEVTLAAHPEATVTNNRVIQPLNGRKVYEYKGEPNDKYNYVQHGFDWRDNGLDSCAGDVQSPIDIVTSTLQAGSSRSDVSSVNLMTLNTDAFTLTGNTVNIGQGMQINFGDPPAGDLPVIRIGTRDVTFRPLQVHWHFFLSEHTVDGVHYPLEAHIVMKDNDNLGDSAGQLAVIGIMYKYGDADPFITDMQKRVSDKIASGAITYGQSGVSLNNPDDPFNVNIKNNFLPSELGYAGYDGSLTTPPCSEIVKWHVFLEPRTVSVEQMEVFADVTLNSNPGATVTTNRMIQPLEGRTVYGYNGAAA",  # Same sequence with slight variations
        "MGSRRITLLGALFAVLAVAIEGRTLLTHNLKAEAAETVDAVSSVVAGSAGRQLLVSEPHDYNYEKVGFDWTGGVCVNTGTSKQSPINIETDSLAEESERLGTADDTSRLALKGLLSSSYQLTSEVAINLEQDMQFSFNAPDEDLPQLTIGGVVHTFKPVQIHFHHFASEHAIDGQLYPLEAHMVMASQNDGSDQLAVIGIMYKYGEEDPFLKRLQETAQSNGEAGDKNVELNSFSINVARDLLPESDLTYYGYDGSLTTPGCDERVKWHVFKEARTVSVAQLKVFSEVTLAAHPEATVTNNRVIQPLNGRKVYEYKGEPNDKYNYVQHGFDWRDNGLDSCAGDVQSPIDIVTSTLQAGSSRSDVSSVNLMTLNTDAFTLTGNTVNIGQGMQINFGDPPAGDLPVIRIGTRDVTFRPLQVHWHFFLSEHTVDGVHYPLEAHIVMKDNDNLGDSAGQLAVIGIMYKYGDADPFITDMQKRVSDKIASGAITYGQSGVSLNNPDDPFNVNIKNNFLPSELGYAGYDGSLTTPPCSEIVKWHVFLEPRTVSVEQMEVFADVTLNSNPGATVTTNRMIQPLEGRTVYGYNGAAA",  # Same sequence with slight variations
        "MGSRRITLLGALFAVLAVAIEGRTLLTHNLKAEAAETVDAVSSVVAGSAGRQLLVSEPHDYNYEKVGFDWTGGVCVNTGTSKQSPINIETDSLAEESERLGTADDTSRLALKGLLSSSYQLTSEVAINLEQDMQFSFNAPDEDLPQLTIGGVVHTFKPVQIHFHHFASEHAIDGQLYPLEAHMVMASQNDGSDQLAVIGIMYKYGEEDPFLKRLQETAQSNGEAGDKNVELNSFSINVARDLLPESDLTYYGYDGSLTTPGCDERVKWHVFKEARTVSVAQLKVFSEVTLAAHPEATVTNNRVIQPLNGRKVYEYKGEPNDKYNYVQHGFDWRDNGLDSCAGDVQSPIDIVTSTLQAGSSRSDVSSVNLMTLNTDAFTLTGNTVNIGQGMQINFGDPPAGDLPVIRIGTRDVTFRPLQVHWHFFLSEHTVDGVHYPLEAHIVMKDNDNLGDSAGQLAVIGIMYKYGDADPFITDMQKRVSDKIASGAITYGQSGVSLNNPDDPFNVNIKNNFLPSELGYAGYDGSLTTPPCSEIVKWHVFLEPRTVSVEQMEVFADVTLNSNPGATVTTNRMIQPLEGRTVYGYNGAAA"   # Same sequence with slight variations
    ]
    return sequences[:n]

@pytest.mark.slow
def test_batch_vs_sequential_prediction():
    # Load model
    calculator = StabilityRewardCalculator()
    
    # Get test sequences
    num_sequences = 4
    sequences = get_sample_sequences(num_sequences)
    
    # Measure sequential prediction time
    sequential_start = time.time()
    sequential_results = []
    with torch.no_grad():
        for seq in sequences:
            output = calculator.predict_structure(seq)
            sequential_results.append(output)
    sequential_time = time.time() - sequential_start
    
    # Measure batched prediction time
    batch_start = time.time()
    with torch.no_grad():
        batched_results = calculator.predict_structure(sequences)
    batch_time = time.time() - batch_start
    
    # Calculate speedup
    speedup = sequential_time / batch_time
    
    print(f"\nSequential prediction time: {sequential_time:.2f}s")
    print(f"Batched prediction time: {batch_time:.2f}s")
    print(f"Speedup factor: {speedup:.2f}x")
    
    # Assert that batching provides some speedup (at least 1.2x faster)
    assert speedup > 1.2, f"Expected batching to be at least 1.2x faster, but got {speedup:.2f}x"
    
    # # Verify that results are similar
    # for seq_result, batch_result in zip(sequential_results, batched_results):
    #     assert torch.allclose(seq_result['positions'], batch_result['positions'], atol=1e-5), \
    #         "Sequential and batched predictions produced different results"

if __name__ == "__main__":
    test_batch_vs_sequential_prediction()